import torch.backends.cudnn as cudnn
import torch.nn.init as init
import torch.utils.data
import torchvision.utils as tvut
import argparse
import torch as nn
from torch.autograd import Variable

from model import VAE
from data_loader import load_data
from train import Trainer
from loss import Loss
import utils

# import pandas as pd 
import numpy as np
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler

# Numpy & Scipy imports
import numpy as np
import scipy
import scipy.misc
import os

def merge_images(sources, k=10):
    """Creates a grid consisting of pairs of columns, where the first column in
    each pair contains images source images and the second column in each pair
    contains images generated by the CycleGAN from the corresponding images in
    the first column.
    """
    _, _, h, w = sources.shape
    # row = int(np.sqrt(10)) # TODO: 10 is the hardcoded batch size
    row = 4
    merged = np.zeros([3, row*h, row*w])
    for idx, s in enumerate(sources):
        
        i = idx // row
        j = idx % row
        merged[:, i*h:(i+1)*h, j*h:(j+1)*h] = s
        # merged[:, i*h:(i+1)*h, (j*2+1)*h:(j*2+2)*h] = t
    return merged.transpose(1, 2, 0)


def save_samples(latent, filename):
    """Saves samples from both generators X->Y and Y->X.
    """
    fake_X = model.decode(latent)

    fake_X = utils.to_data(fake_X)

    merged = merge_images(fake_X)
    path = os.path.join(os.path.join(os.path.dirname(__file__),'generated'), filename)
    scipy.misc.imsave(path, merged)
    print('Saved {}'.format(path))

def save_image(latent, fileroot):
	generated = model.decode(latent)

	generated = utils.to_data(generated)
	for i, image in enumerate(generated):
		scipy.misc.imsave("generated/"+fileroot+str(i)+".png", image.transpose(1, 2, 0))

image_size = 128
num_images = 10
movements = ['Baroque', 'Cubism', 'Minimalism']
color = ['r', 'g', 'b']

data_load_params = {'batch_size' : num_images, 'shuffle' : True, 'cuda': False, 'num_workers' : 1, 'pin_memory' : True,
					'image_size': image_size, 'valid_split': 0.2, 'data_path': './data/touse/',
					'normalize': [[0.57867116, 0.53378844, 0.47493997], [0.2312678, 0.21923426, 0.22560729]]}

train_loader, test_loader = load_data("Pointillism", data_load_params)
model = VAE()
if torch.cuda.is_available():
	model.cuda()
	print('Using GPU')
checkpoint = torch.load('./finalrun/runs/checkpoints/checkpoint2.pth.tar', map_location='cpu')
model.load_state_dict(checkpoint['state_dict'])
for param in model.parameters():
	param.requires_grad = False
model.eval()

images = iter(test_loader).next()
latent_vectors = model.encode(images[0])[0].data.numpy()
categories = images[1].data.numpy()
plt.figure(1)
plt.scatter(latent_vectors[:, 0], latent_vectors[:, 1], c=[color[i] for i in categories])
print("Made first figure")

# mean = np.mean(latent_vectors, axis=0)
# std = np.std(latent_vectors, axis=0)
# print(mean.shape)
# print(std.shape)
# normalized_latent_vectors = (latent_vectors-mean)/std
# print(normalized_latent_vectors.shape)

# # latent_df = pd.DataFrame(latent_vectors)
# # latent_df = StandardScaler().fit_transform(latent_df)
# comps = 10
# pca = PCA(n_components=comps)
# pca.fit(normalized_latent_vectors)
# pca_latent = pca.transform(normalized_latent_vectors)

# # principalDf = pd.DataFrame(data = principalComponents)
# # print(principalDf.head(100))
# # pca_latent = principalDf.values

# print(pca_latent.shape)
# print(pca.components_)
# print(pca.components_.shape)

# fig, axes = plt.subplots(comps, 1, sharex=True, sharey=True)
# plt.setp(axes, xlim=(-20, 20), ylim=(-1, 3), xticks=[-10, -5, 0, 5, 10], yticks=[0, 1, 2], yticklabels=movements)
# for i in range(comps):
# 	# plt.subplot(comps, 1, i+1)
# 	axes[i].scatter(pca_latent[:, i], categories, c=[color[i] for i in categories])
# 	# axes[i].xlim(-10, 10)
# 	# axes[i].ylim(-0.5, 2.5)
# 	# axes[i].yticks([])
# 	# ax.set_ylabel('Component ' + str(i+1))
# 	# ax.set_yticklabels([])
# plt.show()

random_latents = torch.randn(1, 800)
save_image(random_latents, 'random_im.png')
# save_samples(torch.randn(10, 800), 'random3.png')

# centers = np.zeros((3, 800))
# noisy = np.zeros((3, 800))
# for i in range(3):
# 	print(np.where(categories == i))
# 	centers[i, :] = np.mean(latent_vectors[np.where(categories == i)], axis=0)
# 	noisy[i, :] = centers[i, :] + np.random.randn(800)*0.5
# 	print(centers[i, :])

# centers_tensor = torch.from_numpy(noisy).float()
# generated = model.decode(centers_tensor)

# generated = utils.to_data(generated)
# print(generated.shape)
# for i, image in enumerate(generated):
# 	print(image.shape)
# 	scipy.misc.imsave("generated/"+movements[i]+"3.png", image.transpose(1, 2, 0))

translation = False
if translation:
	for ind1 in range(10):
		for ind2 in range(ind1+1, 10):
			diff = latent_vectors[ind2:(ind2+1), :] - latent_vectors[ind1:(ind1+1), :]
			stack = latent_vectors[ind1:(ind1+1), :]
			for i in range(15):
				stack = np.vstack((stack, latent_vectors[ind1:(ind1+1), :]+diff*(i+1)/15))
			stack_tensor = torch.from_numpy(stack).float()

			if not os.path.isdir("generated/"+movements[categories[ind1]]+"To"+movements[categories[ind2]]):
				os.mkdir("generated/"+movements[categories[ind1]]+"To"+movements[categories[ind2]])
				save_samples(stack_tensor, movements[categories[ind1]]+"To"+movements[categories[ind2]]+".png")
				save_image(stack_tensor, movements[categories[ind1]]+"To"+movements[categories[ind2]]+"/")
			else:
				print("already done!")

			randn = np.random.randn(800)*0.5
			diff = latent_vectors[ind2:(ind2+1), :]+np.random.randn(800)*0.5 - latent_vectors[ind1:(ind1+1), :]-randn
			stack = latent_vectors[ind1:(ind1+1), :]+randn
			for i in range(15):
				stack = np.vstack((stack, latent_vectors[ind1:(ind1+1), :]+diff*(i+1)/15))
			stack_tensor = torch.from_numpy(stack).float()
			if not os.path.isdir("generated/"+"Noisy"+movements[categories[ind1]]+"To"+movements[categories[ind2]]):
				os.mkdir("generated/"+"Noisy"+movements[categories[ind1]]+"To"+movements[categories[ind2]])
				save_samples(stack_tensor, "Noisy"+movements[categories[ind1]]+"To"+movements[categories[ind2]]+".png")
				save_image(stack_tensor, "Noisy"+movements[categories[ind1]]+"To"+movements[categories[ind2]]+"/")
			else:
				print('already done noisy!')

			randn = np.random.randn(800)*1
			diff = latent_vectors[ind2:(ind2+1), :]+np.random.randn(800)*1 - latent_vectors[ind1:(ind1+1), :]-randn
			stack = latent_vectors[ind1:(ind1+1), :]+randn
			for i in range(15):
				stack = np.vstack((stack, latent_vectors[ind1:(ind1+1), :]+diff*(i+1)/15))
			stack_tensor = torch.from_numpy(stack).float()
			if not os.path.isdir("generated/"+"VeryNoisy"+movements[categories[ind1]]+"To"+movements[categories[ind2]]):
				os.mkdir("generated/"+"VeryNoisy"+movements[categories[ind1]]+"To"+movements[categories[ind2]])
				save_samples(stack_tensor, "VeryNoisy"+movements[categories[ind1]]+"To"+movements[categories[ind2]]+".png")
				save_image(stack_tensor, "VeryNoisy"+movements[categories[ind1]]+"To"+movements[categories[ind2]]+"/")
			else:
				print('already done noisy!')

# merged = merge_images(fake_X)
# path = os.path.join(os.path.join(os.path.dirname(__file__),'generated'), filename)
# scipy.misc.imsave(path, merged)
# plt.show()

# def train(opts):
# 	training_params = {'num_epochs' : opts.epochs, 'learning_rate' : opts.lr, 'weight_decay' : 0.3, 'learning_rate_decay' : opts.decay, 'cuda' : False, 
# 		'summary_dir' : './runs/logs/', 'checkpoint_dir' : './runs/checkpoints/'}

# 	if opts.checkpoint == 1:
# 		checkpoint = torch.load('./runs/checkpoints/checkpoint2.pth.tar')
# 		model.load_state_dict(checkpoint['state_dict'])

# 	loss = Loss()

# 	trainer = Trainer(model, loss, train_loader, test_loader, training_params)

# 	# print(trainer)

# 	trainer.train(opts)

# # CAUTION: Note that vae_params must be the same as the checkpoint... perhaps we can save this with the checkpoint for future
# def gen_image(checkpoint_file):
# 	checkpoint = torch.load(checkpoint_file)

# 	model.load_state_dict(checkpoint['state_dict'])
# 	print(len(data.train_set))
# 	# print(data.train_set[0][0])
# # <<<<<<< HEAD
# 	print(data.train_set[0][0].size())
# 	batch1 = data.train_set[0][0].unsqueeze(0)
# 	print(batch1.size())
# 	print(batch1)
# 	to_save = data.un_norm(data.train_set[0][0])
# 	tvut.save_image(to_save, "goal1.png")
# 	model.eval()
# 	mu, logvar = model.encode(batch1)
# 	lat = model.reparamaterize(mu, logvar)
# 	print(model.decode(mu)[0])
# 	print(mu)
# 	tvut.save_image(data.un_norm(model.decode(mu)[0]), "generated_image1.png")
# # =======
# # 	# print(data.train_set[0][0].size())
# # 	batch1 = data.train_set[9][0].unsqueeze(0).cuda()
# # 	# print(batch1.size())

# # 	inp = Variable(batch1)
# # 	tvut.save_image(batch1, "goal2.png")
# # 	# print(inp)
# # 	model.eval()
# # 	mu, logvar = model.encode(batch1)
# # 	lat = model.reparamaterize(mu, logvar)
# # >>>>>>> gans
	
# 	# generated = model.decode(mu)

# 	# print(mu, logvar, generated)
# 	# tvut.save_image(generated, "generated_image2.png")
	
# def create_parser():
# 	parser = argparse.ArgumentParser()
# 	parser.add_argument('--images', type = int, default = 100)
# 	return parser


# if __name__ == "__main__":
# 	parser = create_parser()
# 	opts = parser.parse_args()
	
# 	pca_plot(opts)
	# gen_image('./runs/checkpoints/checkpoint2.pth.tar')
